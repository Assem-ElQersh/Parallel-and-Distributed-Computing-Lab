Compile using: g++ -std=c++11 -O3 -o matrix_subtraction 120210321.cpp
The performance comparison of different matrix subtraction methods highlights important trends in memory-bound operations.

1. Serial vs. Parallel Performance
# Serial (0.0188s) & Block Distribution (0.0188s)
	No performance gain from parallelism due to thread overhead and memory bandwidth limits.
# Cyclic Distribution (0.0173s) – Fastest
	Benefits from better memory access patterns, reducing cache conflicts and improving CPU prefetching.
# Block-Cyclic (0.0230s) – Slowest
	Inefficient block size and frequent thread coordination cause higher overhead.
2. Why Cyclic Wins?
Better memory utilization: Strided access improves CPU prefetching and reduces cache conflicts.
Load balancing: Each thread processes an equal workload, avoiding imbalances.
Reduced contention: Threads access non-overlapping memory regions, minimizing interference.

3. Optimization Suggestions
Increase workload per thread (e.g., larger matrices) to reduce thread overhead.
Use SIMD instructions (AVX) for faster element-wise operations.
Optimize block size to align with cache sizes.
Use thread pools to reduce thread creation overhead.

Conclusion
Matrix subtraction is memory-bound, meaning performance is limited by data transfer speed rather than computation.
Parallelism offers little gain unless memory access patterns are optimized.
Cyclic distribution works best because it better utilizes memory bandwidth.
For compute-heavy tasks (e.g., matrix multiplication), block-based approaches would be more effective.